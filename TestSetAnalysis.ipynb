{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import confusion_matrix, brier_score_loss\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "import umap.umap_ as umap # Recommended way to import UMAP\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "from SetRandomSeed import set_random_seeds, GeneratorSeed\n",
    "from zoobot.pytorch.training.finetune import FinetuneableZoobotClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 40)\n",
    "set_random_seeds(626)\n",
    "g = GeneratorSeed(626)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size to match one column in AASTeX (3.25 inches width)\n",
    "width = 3.25\n",
    "height = 2.5 # height can vary, 2.5 inches is just a suggestion\n",
    "matplotlib.rcParams[\"font.size\"] = \"10\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNName = 'Adam_Cyclic' \n",
    "# Load the saved model state\n",
    "checkpoint = torch.load('ResNet_' + CNNName +'.pth', map_location=torch.device('cpu'))\n",
    "model = models.resnet18(weights=True)\n",
    "print(\"Best model was from epoch:\", checkpoint['epoch'])\n",
    "#Set up the model for inference\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 1e-5\n",
    "\n",
    "model = FinetuneableZoobotClassifier(name='hf_hub:mwalmsley/zoobot-encoder-resnet18', learning_rate=learning_rate,  # use a low learning rate\n",
    "    layer_decay=0.5,  # reduce the learning rate from lr to lr^0.5 for each block deeper in the network\n",
    "    # arguments specific to FinetuneableZoobotClassifier\n",
    "    num_classes=2\n",
    ")\n",
    "\n",
    "\n",
    "# Load the model weights from the checkpoint\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to('cpu')  # Ensure the model is on the correct device (GPU/CPU)\n",
    "model.eval()  # Switch to evaluation mode\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BinaryMergerDataset import BinaryMergerDataset, get_transforms\n",
    "path = ### input path here! removed to be anonymous\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use custom data loader to load images, ensuring training has data augmentation and validation and test do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mergers_dataset_orig = BinaryMergerDataset(path, 'test', mergers = True, transform = get_transforms(aug=False), codetest=False)\n",
    "test_nonmergers_dataset_orig = BinaryMergerDataset(path, 'test', mergers = False, transform = get_transforms(aug=False), codetest=False)\n",
    "\n",
    "\n",
    "test_dataset_full = torch.utils.data.ConcatDataset([test_mergers_dataset_orig, test_nonmergers_dataset_orig])\n",
    "# Create a fixed permutation\n",
    "indices = np.random.permutation(len(test_dataset_full))\n",
    "shuffled_test_dataset = Subset(test_dataset_full, indices)\n",
    "\n",
    "test_dataloader = DataLoader(shuffled_test_dataset, shuffle = False, num_workers = 0, batch_size=BATCH_SIZE, generator=g)\n",
    "\n",
    "train_mergers_dataset_augment = BinaryMergerDataset(path, 'train', mergers = True, transform = get_transforms(aug=True), codetest=False)\n",
    "train_nonmergers_dataset_augment = BinaryMergerDataset(path, 'train', mergers = False, transform = get_transforms(aug=True), codetest=False)\n",
    "\n",
    "train_mergers_dataset_orig = BinaryMergerDataset(path, 'train', mergers = True, transform = get_transforms(aug=False), codetest=False)\n",
    "train_nonmergers_dataset_orig = BinaryMergerDataset(path, 'train', mergers = False, transform = get_transforms(aug=False), codetest=False)\n",
    "\n",
    "train_dataset_full = torch.utils.data.ConcatDataset([train_mergers_dataset_augment, train_nonmergers_dataset_augment, train_mergers_dataset_orig, train_nonmergers_dataset_orig])\n",
    "train_dataloader = DataLoader(train_dataset_full, shuffle = True, num_workers = 0, batch_size=BATCH_SIZE, generator=g)\n",
    "\n",
    "validation_mergers_dataset_orig = BinaryMergerDataset(path, 'validation', mergers = True, transform = get_transforms(aug=False), codetest=False)\n",
    "validation_nonmergers_dataset_orig = BinaryMergerDataset(path, 'validation', mergers = False, transform = get_transforms(aug=False), codetest=False)\n",
    "\n",
    "validation_dataset_full = torch.utils.data.ConcatDataset([validation_mergers_dataset_orig, validation_nonmergers_dataset_orig])\n",
    "validation_dataloader = DataLoader(validation_dataset_full, shuffle = False, num_workers = 0, batch_size=BATCH_SIZE, generator=g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_mergers_dataset_orig) + len(train_mergers_dataset_augment))\n",
    "print(len(train_nonmergers_dataset_orig) + len(train_nonmergers_dataset_augment))\n",
    "\n",
    "print(len(validation_mergers_dataset_orig))\n",
    "print(len(validation_nonmergers_dataset_orig))\n",
    "\n",
    "print(len(test_mergers_dataset_orig))\n",
    "print(len(test_nonmergers_dataset_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define accuracy and a confusion matrix \n",
    "def get_accuracy(pred,original):\n",
    "    print(pred, original)\n",
    "    return np.mean(pred == original) * 100\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, epoch): #help from chat GPT\n",
    "    plt.figure(figsize=(width, width))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap='Purples', xticklabels=classes, yticklabels=classes, vmin = 0, vmax = 100,\n",
    "                square = True, cbar_kws={'label': 'Percentage', \"shrink\": 0.65})\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    #plt.title('Confusion Matrix ' + str(epoch) + ' Set')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ConfusionMatrix_TestSet_' + CNNName +'.png', dpi = 300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print names of nodes I could pull to plot -- we are looking for the name of the fully connected layer for UMAP\n",
    "print(get_graph_node_names(model))\n",
    "feature_extractor_model = create_feature_extractor(model, return_nodes={'encoder.fc': 'extracted_features',})\n",
    "\n",
    "# Set the feature extractor model to evaluation mode\n",
    "feature_extractor_model.eval()\n",
    "feature_extractor_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_preds = []\n",
    "all_names = []\n",
    "all_probabilities = []\n",
    "all_logits = []\n",
    "all_extracted_features = []\n",
    "all_labels_for_isomap_plot = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():  # No need to track gradients during inference\n",
    "    for images, labels, names in tqdm(test_dataloader):\n",
    "        images = images.to(dtype=torch.float32).to(device) \n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        all_logits.extend(outputs.cpu().numpy())\n",
    "        features_dict = feature_extractor_model(images)\n",
    "        features = features_dict['extracted_features']\n",
    "\n",
    "        # The output of avgpool is usually [N, 512, 1, 1]. Flatten it.\n",
    "        features = torch.flatten(features, 1) # Flattens to [N, 512]\n",
    "        \n",
    "        all_extracted_features.extend(features.cpu().numpy())\n",
    "        all_labels_for_isomap_plot.extend(labels.cpu().numpy())\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        pred = torch.argmax(outputs, dim=1)   # Convert to binary (0 or 1)\n",
    "        pred = pred.to(device=device) \n",
    "        maxvals, pred_index = torch.max(outputs, 1)\n",
    "        # Collect labels and predictions\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_names.extend(names)\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())\n",
    "# 4. Compute accuracy or other evaluation metrics (e.g., confusion matrix)\n",
    "# Convert lists to numpy arrays\n",
    "all_labels = np.array(all_labels)\n",
    "#all_preds = np.squeeze(np.array(all_preds))\n",
    "all_preds = np.array(all_preds)\n",
    "all_names = np.array(all_names)\n",
    "all_probabilities = np.array(all_probabilities)\n",
    "all_logits = np.array(all_logits)\n",
    "test_accuracy = get_accuracy(all_preds, all_labels)\n",
    "all_extracted_features = np.array(all_extracted_features)\n",
    "all_labels_for_isomap_plot = np.array(all_labels_for_isomap_plot)\n",
    "#test_accuracy = np.mean(np.array(test_acc))\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(test_accuracy)\n",
    "\n",
    "print(\"Best model was from epoch:\", checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_names = np.array(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cmn = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]) *100 \n",
    "TP, FN, FP, TN = cm.ravel()\n",
    "plot_confusion_matrix(cmn, classes=['Merger', 'Non-merger'], epoch='Test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purity = TP / (TP + FP)\n",
    "completeness = TP / (TP + FN)\n",
    "print(purity, completeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(all_labels))\n",
    "print(np.shape(all_probabilities[:,0]))\n",
    "print(np.max(all_probabilities[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "for i in range(len(all_preds)):\n",
    "    if all_preds[i] == all_labels[i]:\n",
    "        correct.append('yes')\n",
    "    else:\n",
    "        correct.append('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '102575_1'\n",
    "string[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a big data frame for statistics of which galaxies are identified correctly from which angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationInfo = pd.DataFrame(all_names, columns=['Image Name'])\n",
    "ClassificationInfo['True Label'] = all_labels\n",
    "ClassificationInfo['Predicted Label'] = all_preds\n",
    "ClassificationInfo['Correct?'] = correct\n",
    "\n",
    "\n",
    "ClassificationInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shids = []\n",
    "for n in ClassificationInfo['Image Name']:\n",
    "    #print(n[:-2])\n",
    "    shids.append(n[:-2])\n",
    "ClassificationInfo['SubhaloID'] = np.array(shids).astype(int)\n",
    "shids = list(set(shids))\n",
    "shids = np.array(shids).astype(int)\n",
    "print(shids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shids.sort()\n",
    "print(shids)\n",
    "print(type(shids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationInfo = ClassificationInfo.sort_values(by='SubhaloID')\n",
    "ClassificationInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table40 = pd.read_csv('/code/SubhaloListForMakeMocks40.csv', usecols = ['Subfind_ID', 'Type'])\n",
    "table50 = pd.read_csv('/code/SubhaloListForMakeMocks50.csv', usecols = ['Subfind_ID', 'Type'])\n",
    "bigtable = pd.concat([table40, table50], ignore_index=False)\n",
    "bigtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(bigtable['Subfind_ID'][0]))\n",
    "print(type(shids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types =[]\n",
    "for s in shids:\n",
    "    #print(type(s))\n",
    "    limit = 6\n",
    "    result = bigtable.loc[bigtable['Subfind_ID'] == s, 'Type'].values[0]\n",
    "    print(result)\n",
    "    while limit != 0:\n",
    "        types.append(result)\n",
    "        limit-=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(types))\n",
    "ClassificationInfo['Type'] = types\n",
    "ClassificationInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Merger Mass Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_main = 40\n",
    "s = 40\n",
    "Subfind_ID_mergers40 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/all_mergers_at_' + str(s) + '_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 1, dtype = int)\n",
    "Subfind_ID_nonmergers40 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/nonmergers_matched_at_' + str(s) + '_no_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 1, dtype = int)\n",
    "q_mergers40 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/all_mergers_at_' + str(s) + '_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 3, dtype = float)\n",
    "sm_mergers40 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/all_mergers_at_' + str(s) + '_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 5, dtype = float)\n",
    "sm_nonmergers40 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/nonmergers_matched_at_' + str(s) + '_no_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 2, dtype = float)\n",
    "sfr_mergers40 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/all_mergers_at_' + str(s) + '_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 8, dtype = float)\n",
    "sfr_nonmergers40 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/nonmergers_matched_at_' + str(s) + '_no_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 3, dtype = float)\n",
    "\n",
    "s_main = 50\n",
    "s = 50\n",
    "Subfind_ID_mergers50 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/all_mergers_at_' + str(s) + '_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 1, dtype = int)\n",
    "Subfind_ID_nonmergers50 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/nonmergers_matched_at_' + str(s) + '_no_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 1, dtype = int)\n",
    "q_mergers50 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/all_mergers_at_' + str(s) + '_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 3, dtype = float)\n",
    "sm_mergers50 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/all_mergers_at_' + str(s) + '_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 5, dtype = float)\n",
    "sm_nonmergers50 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/nonmergers_matched_at_' + str(s) + '_no_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 2, dtype = float)\n",
    "sfr_mergers50 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/all_mergers_at_' + str(s) + '_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 8, dtype = float)\n",
    "sfr_nonmergers50 = np.loadtxt('/TNGProjects/merger_tables/' + str(s_main) + '/nonmergers_matched_at_' + str(s) + '_no_enviro.txt', \n",
    "                                    skiprows = 1, usecols = 3, dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sfr_nonmergers40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q= []\n",
    "sm = []\n",
    "sfr = []\n",
    "Subfind_ID = np.concatenate((Subfind_ID_mergers40, Subfind_ID_mergers50))\n",
    "Subfind_ID_nonmergers = np.concatenate((Subfind_ID_nonmergers40, Subfind_ID_nonmergers50))\n",
    "q_mergers = np.concatenate((q_mergers40, q_mergers50))\n",
    "sm_mergers = np.concatenate((sm_mergers40, sm_mergers50))\n",
    "sm_nonmergers = np.concatenate((sm_nonmergers40, sm_nonmergers50))\n",
    "sfr_mergers = np.concatenate((sfr_mergers40, sfr_mergers50))\n",
    "sfr_nonmergers = np.concatenate((sfr_nonmergers40, sfr_nonmergers50))\n",
    "for s in shids:\n",
    "    #print(type(s))\n",
    "    limit = 6\n",
    "    if s in Subfind_ID:\n",
    "        index = np.where(Subfind_ID == s)[0][0]\n",
    "        #print(index[0][0])\n",
    "        ratio = q_mergers[index]\n",
    "        stellarmass = np.log10(sm_mergers[index])\n",
    "        starformation = sfr_mergers[index]\n",
    "        if ratio < 1:\n",
    "            while limit != 0:\n",
    "                q.append(ratio)\n",
    "                sm.append(stellarmass) \n",
    "                sfr.append(starformation)\n",
    "                limit-=1     \n",
    "        else:\n",
    "            while limit != 0:\n",
    "                q.append(1/ratio)\n",
    "                sm.append(stellarmass) \n",
    "                sfr.append(starformation)\n",
    "                limit-=1\n",
    "    else:\n",
    "        index = np.where(Subfind_ID_nonmergers == s)[0][0]\n",
    "        while limit != 0:\n",
    "            q.append(0.0)\n",
    "            stellarmass = np.log10(sm_nonmergers[index])\n",
    "            sm.append(stellarmass) \n",
    "            starformation = sfr_nonmergers[index]\n",
    "            sfr.append(starformation)\n",
    "            limit-=1\n",
    "\n",
    "q_name = []\n",
    "for r in q:\n",
    "    if r== 0.0:\n",
    "        q_name.append('non')\n",
    "    elif r >= 0.25:\n",
    "        q_name.append('major')\n",
    "    else: \n",
    "        q_name.append('minor')\n",
    "#print(len(q))\n",
    "ClassificationInfo['Mass Ratio'] = q\n",
    "ClassificationInfo['Ratio Name'] = q_name\n",
    "ClassificationInfo['Stellar Mass'] = sm\n",
    "ClassificationInfo['SFR'] = sfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_class = []\n",
    "t_class = []\n",
    "\n",
    "for l in ClassificationInfo['True Label']:\n",
    "    if l == 0.0:\n",
    "        t_class.append('merger')\n",
    "    else:\n",
    "        t_class.append('nonmerger')\n",
    "\n",
    "for l in ClassificationInfo['Predicted Label']:\n",
    "    if l == 0.0:\n",
    "        p_class.append('merger')\n",
    "    else:\n",
    "        p_class.append('nonmerger')\n",
    "\n",
    "ClassificationInfo['True Class'] = t_class\n",
    "ClassificationInfo['Predicted Class'] = p_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationInfo = ClassificationInfo.loc[:, ['SubhaloID', 'Image Name', 'True Class', 'Predicted Class', 'True Label', 'Predicted Label', 'Correct?', 'Type', 'Mass Ratio', 'Ratio Name', 'Stellar Mass', 'SFR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassificationInfo.to_csv('CNN_ResultsTable_' + CNNName + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do we do on major vs minor mergers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmergers = ClassificationInfo[ClassificationInfo['Mass Ratio'] != 0.0]\n",
    "allmergers_correct = allmergers[allmergers['Correct?'] == 'yes']\n",
    "allmergers_accuracy = np.round(len(allmergers_correct)/len(allmergers) *100, 2)\n",
    "print(allmergers_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major = ClassificationInfo[ClassificationInfo['Ratio Name'] == 'major']\n",
    "minor = ClassificationInfo[ClassificationInfo['Ratio Name'] == 'minor']\n",
    "non = ClassificationInfo[ClassificationInfo['Ratio Name'] == 'non']\n",
    "\n",
    "major_correct = major[major['Correct?'] == 'yes']\n",
    "minor_correct = minor[minor['Correct?'] == 'yes']\n",
    "non_correct = non[non['Correct?'] == 'yes']\n",
    "\n",
    "major_accuracy = np.round(len(major_correct)/len(major) *100, 2)\n",
    "minor_accuracy = np.round(len(minor_correct)/len(minor)*100, 2)\n",
    "non_accuracy = np.round(len(non_correct)/len(non)*100, 2)\n",
    "\n",
    "print(major_accuracy)\n",
    "print(minor_accuracy)\n",
    "print(non_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects = ClassificationInfo[ClassificationInfo['Correct?'] == 'yes']\n",
    "print(len(corrects)/len(ClassificationInfo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do we do on different merger stages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger= ClassificationInfo[ClassificationInfo['Type'] == 'Merger']\n",
    "early = ClassificationInfo[(ClassificationInfo['Type'] == 'first_progenitor') | (ClassificationInfo['Type'] == 'next_progenitor')] #| is or but better for this case\n",
    "late = ClassificationInfo[ClassificationInfo['Type'] == 'Descendant']\n",
    "\n",
    "merger_correct = merger[merger['Correct?'] == 'yes']\n",
    "early_correct = early[early['Correct?'] == 'yes']\n",
    "late_correct = late[late['Correct?'] == 'yes']\n",
    "\n",
    "merger_accuracy = np.round(len(merger_correct)/len(merger) *100,2)\n",
    "early_accuracy = np.round(len(early_correct)/len(early)*100,2)\n",
    "late_accuracy = np.round(len(late_correct)/len(late)*100,2)\n",
    "\n",
    "\n",
    "\n",
    "print(merger_accuracy)\n",
    "print(early_accuracy)\n",
    "print(late_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = ClassificationInfo[(ClassificationInfo['Type'] == 'Merger') | (ClassificationInfo['Type'] == 'Descendant')] #| is or but better for this case\n",
    "post_correct = post[post['Correct?'] == 'yes']\n",
    "post_accuracy = len(post_correct)/len(post)\n",
    "print(post_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which galaxies are classified correctly from every angle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_angle_correct = []\n",
    "for s in shids:\n",
    "    s = s.astype(str)\n",
    "    angle1 = s+'_1'\n",
    "    angle2 = s+'_2'\n",
    "    angle3 = s+'_3'\n",
    "    angle4 = s+'_4'\n",
    "    angle5 = s+'_5'\n",
    "    angle6 = s+'_6'\n",
    "    a1 = ClassificationInfo[ClassificationInfo['Image Name'] == angle1]\n",
    "    a2 = ClassificationInfo[ClassificationInfo['Image Name'] == angle2]\n",
    "    a3 = ClassificationInfo[ClassificationInfo['Image Name'] == angle3]\n",
    "    a4 = ClassificationInfo[ClassificationInfo['Image Name'] == angle4]\n",
    "    a5 = ClassificationInfo[ClassificationInfo['Image Name'] == angle5]\n",
    "    a6 = ClassificationInfo[ClassificationInfo['Image Name'] == angle6]\n",
    "    \n",
    "    if a1['Correct?'].values[0] == 'yes' and a2['Correct?'].values[0] == 'yes' and a2['Correct?'].values[0] == 'yes'\\\n",
    "        and a4['Correct?'].values[0] == 'yes' and a5['Correct?'].values[0] == 'yes' and a6['Correct?'].values[0] == 'yes':\n",
    "        every_angle_correct.append(int(s))\n",
    "    #print(a1['Correct?'].values[0])\n",
    "#ClassificationInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(every_angle_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EveryAngleCorrect = ClassificationInfo[ClassificationInfo['SubhaloID'].isin(every_angle_correct)]\n",
    "EveryAngleCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EveryAngleCorrect.to_csv('EveryAngleCorrect_' + CNNName + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which galaxies are classified wrong from every angle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_angle_wrong = []\n",
    "for s in shids:\n",
    "    s = s.astype(str)\n",
    "    angle1 = s+'_1'\n",
    "    angle2 = s+'_2'\n",
    "    angle3 = s+'_3'\n",
    "    angle4 = s+'_4'\n",
    "    angle5 = s+'_5'\n",
    "    angle6 = s+'_6'\n",
    "    a1 = ClassificationInfo[ClassificationInfo['Image Name'] == angle1]\n",
    "    a2 = ClassificationInfo[ClassificationInfo['Image Name'] == angle2]\n",
    "    a3 = ClassificationInfo[ClassificationInfo['Image Name'] == angle3]\n",
    "    a4 = ClassificationInfo[ClassificationInfo['Image Name'] == angle4]\n",
    "    a5 = ClassificationInfo[ClassificationInfo['Image Name'] == angle5]\n",
    "    a6 = ClassificationInfo[ClassificationInfo['Image Name'] == angle6]\n",
    "    \n",
    "    if a1['Correct?'].values[0] == 'no' and a2['Correct?'].values[0] == 'no' and a2['Correct?'].values[0] == 'no'\\\n",
    "        and a4['Correct?'].values[0] == 'no' and a5['Correct?'].values[0] == 'no' and a6['Correct?'].values[0] == 'no':\n",
    "        every_angle_wrong.append(int(s))\n",
    "    #print(a1['Correct?'].values[0])\n",
    "#ClassificationInfo\n",
    "print(every_angle_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EveryAngleWrong = ClassificationInfo[ClassificationInfo['SubhaloID'].isin(every_angle_wrong)]\n",
    "EveryAngleWrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EveryAngleWrong.to_csv('EveryAngleWrong_' + CNNName + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the average number of correct angles per galaxy? Does this change with mass ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_angle_correct = []\n",
    "num_angle_correct_nm = []\n",
    "mass_ratio = []\n",
    "for s in shids:\n",
    "    s = s.astype(str)\n",
    "    angle1 = s+'_1'\n",
    "    angle2 = s+'_2'\n",
    "    angle3 = s+'_3'\n",
    "    angle4 = s+'_4'\n",
    "    angle5 = s+'_5'\n",
    "    angle6 = s+'_6'\n",
    "    a1 = ClassificationInfo[ClassificationInfo['Image Name'] == angle1]\n",
    "    a2 = ClassificationInfo[ClassificationInfo['Image Name'] == angle2]\n",
    "    a3 = ClassificationInfo[ClassificationInfo['Image Name'] == angle3]\n",
    "    a4 = ClassificationInfo[ClassificationInfo['Image Name'] == angle4]\n",
    "    a5 = ClassificationInfo[ClassificationInfo['Image Name'] == angle5]\n",
    "    a6 = ClassificationInfo[ClassificationInfo['Image Name'] == angle6]\n",
    "    count = 0\n",
    "    for a in [a1, a2, a3, a4, a5, a6]:\n",
    "        if a['Correct?'].values[0] == 'yes':\n",
    "            count+=1\n",
    "    num_angle_correct.append(count)\n",
    "    mass_ratio.append(a['Mass Ratio'].values[0])\n",
    "num_angle_correct = np.array(num_angle_correct) \n",
    "mass_ratio = np.array(mass_ratio)     \n",
    "print(np.mean(np.array(num_angle_correct)))    \n",
    "print(np.median(np.array(num_angle_correct)))    \n",
    "print(np.std(np.array(num_angle_correct)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(-0.5,7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.where(mass_ratio != 0.0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_angle_correct[~inds])\n",
    "print(num_angle_correct[inds])\n",
    "print(np.mean(num_angle_correct[inds]))\n",
    "print(np.median(num_angle_correct[inds]))\n",
    "\n",
    "print(np.mean(num_angle_correct[~inds]))\n",
    "print(np.median(num_angle_correct[~inds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_df_q = pd.DataFrame([])\n",
    "angles_df_q['Number of Angles Correctly Classified'] = num_angle_correct[inds]\n",
    "angles_df_q['Mass Ratio'] = mass_ratio[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_q_ax2_ylabels = []\n",
    "for c in range(7):\n",
    "    count = len(angles_df_q[angles_df_q['Number of Angles Correctly Classified'] == c])\n",
    "    angles_q_ax2_ylabels.append(str(count))\n",
    "\n",
    "print(angles_q_ax2_ylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6), constrained_layout= True)\n",
    "sns.boxplot(data = angles_df_q, x=\"Mass Ratio\", y = \"Number of Angles Correctly Classified\", \n",
    "            dodge = False, orient = 'h', palette='Purples').set(xlabel = 'Merger Mass Ratio')\n",
    "ax.axvline(x = 0.25, ymin = 0, ymax = 1, color = 'black', linestyle = ':')\n",
    "ax.set_xlabel('Merger Mass Ratio', fontsize = 'x-large')\n",
    "ax.set_ylabel(\"Number of Angles Correctly Classified\", fontsize = 'x-large')\n",
    "ax.tick_params(labelsize = 'x-large')\n",
    "plt.ylim(-.9, 6.9)\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylim(ax.get_ylim())\n",
    "ax2.set_yticks(ax.get_yticks())\n",
    "ax2.tick_params(axis=u'both', which=u'both',length=0, labelsize = 'x-large')\n",
    "ax2.set_yticklabels(angles_q_ax2_ylabels)\n",
    "ax2.set_ylabel('Number of Galaxies in Bin', fontsize = 'x-large')\n",
    "plt.savefig('AnglesCorrect_MassRatio' + CNNName + '.png', dpi = 300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the average number of angles correct based on mass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_angle_correct = []\n",
    "num_angle_correct_nm = []\n",
    "mass = []\n",
    "for s in shids:\n",
    "    s = s.astype(str)\n",
    "    angle1 = s+'_1'\n",
    "    angle2 = s+'_2'\n",
    "    angle3 = s+'_3'\n",
    "    angle4 = s+'_4'\n",
    "    angle5 = s+'_5'\n",
    "    angle6 = s+'_6'\n",
    "    a1 = ClassificationInfo[ClassificationInfo['Image Name'] == angle1]\n",
    "    a2 = ClassificationInfo[ClassificationInfo['Image Name'] == angle2]\n",
    "    a3 = ClassificationInfo[ClassificationInfo['Image Name'] == angle3]\n",
    "    a4 = ClassificationInfo[ClassificationInfo['Image Name'] == angle4]\n",
    "    a5 = ClassificationInfo[ClassificationInfo['Image Name'] == angle5]\n",
    "    a6 = ClassificationInfo[ClassificationInfo['Image Name'] == angle6]\n",
    "    count = 0\n",
    "    for a in [a1, a2, a3, a4, a5, a6]:\n",
    "        if a['Correct?'].values[0] == 'yes':\n",
    "            count+=1\n",
    "    num_angle_correct.append(count)\n",
    "    mass.append(a['Stellar Mass'].values[0])\n",
    "num_angle_correct = np.array(num_angle_correct) \n",
    "mass = np.array(mass)     \n",
    "print(np.mean(np.array(num_angle_correct)))    \n",
    "print(np.median(np.array(num_angle_correct)))    \n",
    "print(np.std(np.array(num_angle_correct)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.where(mass_ratio != 0.0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_df_sm_mergers = pd.DataFrame([])\n",
    "angles_df_sm_mergers['Number of Angles Correctly Classified'] = num_angle_correct[inds]\n",
    "angles_df_sm_mergers['Stellar Mass'] = mass[inds]\n",
    "\n",
    "angles_df_sm_nonmergers = pd.DataFrame([])\n",
    "angles_df_sm_nonmergers['Number of Angles Correctly Classified'] = num_angle_correct[~inds]\n",
    "angles_df_sm_nonmergers['Stellar Mass'] = mass[~inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_sm_mergers_ax2_ylabels = []\n",
    "for c in range(7):\n",
    "    count = len(angles_df_sm_mergers[angles_df_sm_mergers['Number of Angles Correctly Classified'] == c])\n",
    "    angles_sm_mergers_ax2_ylabels.append(str(count))\n",
    "\n",
    "print(angles_sm_mergers_ax2_ylabels)\n",
    "\n",
    "angles_sm_nonmergers_ax2_ylabels = []\n",
    "for c in range(7):\n",
    "    count = len(angles_df_sm_nonmergers[angles_df_sm_nonmergers['Number of Angles Correctly Classified'] == c])\n",
    "    angles_sm_nonmergers_ax2_ylabels.append(str(count))\n",
    "\n",
    "print(angles_sm_nonmergers_ax2_ylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6), constrained_layout=True)\n",
    "sns.boxplot(data = angles_df_sm_mergers, x=\"Stellar Mass\", y = \"Number of Angles Correctly Classified\", \n",
    "            dodge = False, orient = 'h', palette='Purples').set(xlabel = r\"M$_\\star$ of Merger [LogM$_\\odot$]\")\n",
    "plt.ylim(-.9, 6.9)\n",
    "ax.set_xlabel(r\"M$_\\star$ of Merger [LogM$_\\odot$]\", fontsize = 'x-large')\n",
    "ax.set_ylabel(\"Number of Angles Correctly Classified\",fontsize = 'x-large')\n",
    "ax.tick_params(labelsize = 'x-large')\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylim(ax.get_ylim())\n",
    "ax2.set_yticks(ax.get_yticks())\n",
    "ax2.tick_params(axis=u'both', which=u'both',length=0, labelsize = 'x-large')\n",
    "ax2.set_yticklabels(angles_sm_mergers_ax2_ylabels, fontsize = 'x-large')\n",
    "ax2.set_ylabel('Number of Galaxies in Bin', fontsize = 'x-large')\n",
    "#plt.tight_layout()\n",
    "plt.savefig('AnglesCorrect_StellarMass_Merger' + CNNName + '.png', dpi = 300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (8,6), constrained_layout=True)\n",
    "sns.boxplot(data = angles_df_sm_nonmergers, x=\"Stellar Mass\", y = \"Number of Angles Correctly Classified\", \n",
    "            dodge = False, orient = 'h', palette='Purples').set(xlabel = r\"M$_\\star$ of Nonmerger [LogM$_\\odot$]\",)\n",
    "plt.ylim(-.9, 6.9)\n",
    "ax.set_xlabel(r\"M$_\\star$ of Nonmerger [LogM$_\\odot$]\", fontsize = 'x-large')\n",
    "ax.set_ylabel(\"Number of Angles Correctly Classified\",fontsize = 'x-large')\n",
    "ax.tick_params(labelsize = 'x-large')\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylim(ax.get_ylim())\n",
    "ax2.set_yticks(ax.get_yticks())\n",
    "ax2.tick_params(axis=u'both', which=u'both',length=0, labelsize = 'x-large')\n",
    "ax2.set_yticklabels(angles_sm_nonmergers_ax2_ylabels, fontsize = 'x-large')\n",
    "ax2.set_ylabel('Number of Galaxies in Bin', fontsize = 'x-large')\n",
    "#plt.tight_layout()\n",
    "plt.savefig('AnglesCorrect_StellarMass_Nonmerger' + CNNName + '.png', dpi = 300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brier Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brier = brier_score_loss(y_true = all_labels, y_proba = all_probabilities[:,0], pos_label = 0)\n",
    "print(brier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Calibration Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidences = probabiliies (I think we use all_probabilities here)\n",
    "print(all_probabilities)\n",
    "print(np.min(all_probabilities))\n",
    "print(type(all_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/expected-calibration-error-ece-a-step-by-step-visual-explanation-with-python-code-c3e9aa12937d/\n",
    "def ECE(samples, labels, numbins = 10):\n",
    "    # uniform binning approach with M number of bins\n",
    "    bin_boundaries = np.linspace(0, 1, numbins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    \n",
    "    # get max probability per sample i\n",
    "    confidences = np.max(samples, axis=1)\n",
    "    # get predictions from confidences (positional in this case)\n",
    "    predicted_label = np.argmax(samples, axis=1)\n",
    "    \n",
    "    # get a boolean list of correct/false predictions\n",
    "    accuracies = predicted_label==labels\n",
    "\n",
    "    ece = np.zeros(1)\n",
    "    bin_accs = []\n",
    "    bin_confs = []\n",
    "    bin_nums = [] \n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # determine if sample is in bin m (between bin lower &amp; upper)\n",
    "        in_bin = np.logical_and(confidences > bin_lower.item(), confidences <= bin_upper.item())\n",
    "        nums= in_bin.sum()\n",
    "        # can calculate the empirical probability of a sample falling into bin m: (|Bm|/n)\n",
    "        prob_in_bin = in_bin.mean()\n",
    "\n",
    "        if prob_in_bin.item() > 0:\n",
    "            bin_nums.append(nums)\n",
    "            # get the accuracy of bin m: acc(Bm)\n",
    "            accuracy_in_bin = accuracies[in_bin].mean()\n",
    "            bin_accs.append(accuracy_in_bin)\n",
    "            # get the average confidence of bin m: conf(Bm)\n",
    "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "            bin_confs.append(avg_confidence_in_bin)\n",
    "            # calculate |acc(Bm) - conf(Bm)| * (|Bm|/n) for bin m and add to the total ECE\n",
    "            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prob_in_bin\n",
    "        else:\n",
    "            bin_accs.append(np.nan)\n",
    "            bin_confs.append(np.nan)\n",
    "            bin_nums.append(np.nan)\n",
    "    return ece, np.array(bin_accs), np.array(bin_confs), bin_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ece, accs, confs, nums = ECE(all_probabilities, all_labels)\n",
    "gap = confs - accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accs)\n",
    "\n",
    "bin_boundaries = np.linspace(0, 1, 10 + 1)\n",
    "bin_lowers = bin_boundaries[:-1]\n",
    "bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "bin_centers = ((bin_uppers - bin_lowers) /2) + bin_boundaries[:-1]\n",
    "print(bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.colormaps['magma']\n",
    "\n",
    "mergers_color = cmap(0.2)\n",
    "nonmergers_color = cmap(0.7)\n",
    "colors = [mergers_color, nonmergers_color]  # List of colors\n",
    "cmap_name = \"my_cmap\"  # Name for your colormap\n",
    "cmap_binary = LinearSegmentedColormap.from_list(cmap_name, colors)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(np.shape(all_extracted_features))\n",
    "print(np.shape(all_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_names[0])\n",
    "print(all_labels_for_isomap_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom labels\n",
    "wordlabels = []\n",
    "\n",
    "for l in range(len(all_labels_for_isomap_plot)):\n",
    "    if [l] == 0:\n",
    "        wordlabels.append('merger')\n",
    "    else:\n",
    "        wordlabels.append('nonmerger')\n",
    "        \n",
    "print(wordlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_labels) == np.array(all_labels_for_isomap_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualize the Isomap embedding (optional, but helpful)\n",
    "merger_mask = (all_labels_for_isomap_plot == 0)\n",
    "nonmerger_mask = (all_labels_for_isomap_plot == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom pred labels\n",
    "pred_wordlabels = []\n",
    "\n",
    "for l in range(len(all_preds)):\n",
    "    if all_preds[l] == 0:\n",
    "        pred_wordlabels.append('merger')\n",
    "    else:\n",
    "        pred_wordlabels.append('nonmerger')\n",
    "        \n",
    "print(pred_wordlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses_in_order = []\n",
    "\n",
    "for name in all_names:\n",
    "    mass = ClassificationInfo.loc[ClassificationInfo['Image Name'] == str(name), 'Stellar Mass'].iloc[0]\n",
    "    masses_in_order.append(mass)\n",
    "masses_in_order = np.array(masses_in_order)\n",
    "norm_mass = Normalize(vmin=np.min(masses_in_order), vmax=np.max(masses_in_order)+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_in_order = []\n",
    "\n",
    "for name in all_names:\n",
    "    ratio = ClassificationInfo.loc[ClassificationInfo['Image Name'] == str(name), 'Mass Ratio'].iloc[0]\n",
    "    ratios_in_order.append(ratio)\n",
    "    \n",
    "print(ratios_in_order)\n",
    "ratios_in_order = np.array(ratios_in_order)\n",
    "zero_ratio_indices = np.where(ratios_in_order == 0.0)[0]\n",
    "non_zero_ratio_indices = np.where(ratios_in_order != 0.0)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_in_order = []\n",
    "\n",
    "for name in all_names:\n",
    "    typeofmerg = ClassificationInfo.loc[ClassificationInfo['Image Name'] == str(name), 'Type'].iloc[0]\n",
    "    types_in_order.append(typeofmerg)\n",
    "    \n",
    "print(types_in_order)\n",
    "types_in_order = np.array(types_in_order)\n",
    "nostage = np.where(types_in_order == '0.0')[0]\n",
    "earlystage = np.where((types_in_order == 'first_progenitor') | (types_in_order == 'next_progenitor'))[0]\n",
    "latestage = np.where((types_in_order == 'Merger') | (types_in_order == 'Descendant'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrs_in_order = []\n",
    "\n",
    "for name in all_names:\n",
    "    sfr = ClassificationInfo.loc[ClassificationInfo['Image Name'] == str(name), 'SFR'].iloc[0]\n",
    "    sfrs_in_order.append(sfr)\n",
    "    \n",
    "log_sfr_array = np.log10(np.array(sfrs_in_order))\n",
    "norm_sfr = Normalize(vmin=np.min(log_sfr_array), vmax=np.max(log_sfr_array))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrs_in_order = []\n",
    "\n",
    "for name in all_names:\n",
    "    sfr = ClassificationInfo.loc[ClassificationInfo['Image Name'] == str(name), 'SFR'].iloc[0]\n",
    "    sfrs_in_order.append(sfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrs_in_order = []\n",
    "\n",
    "for name in all_names:\n",
    "    sfr = ClassificationInfo.loc[ClassificationInfo['Image Name'] == str(name), 'SFR'].iloc[0]\n",
    "    sfrs_in_order.append(sfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses_in_order = []\n",
    "\n",
    "for name in all_names:\n",
    "    mass = ClassificationInfo.loc[ClassificationInfo['Image Name'] == str(name), 'Stellar Mass'].iloc[0]\n",
    "    masses_in_order.append(mass)\n",
    "masses_in_order = np.array(masses_in_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_components=2, n_neighbors=15, random_state=626)\n",
    "\n",
    "umap_embedding = reducer.fit_transform(all_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"UMAP embedding shape:\", umap_embedding.shape) # Should be (num_samples, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Define custom labels for the legend\n",
    "custom_labels = {0: 'Merger', 1: 'Non-merger'}\n",
    "legend_labels = [custom_labels[label] for label in sorted(np.unique(all_labels))]\n",
    "\n",
    "# You can color the points by their true labels (all_labels)\n",
    "# or by predicted labels (all_preds) to see how well they separate.\n",
    "scatter = plt.scatter(\n",
    "    umap_embedding[:, 0],\n",
    "    umap_embedding[:, 1],\n",
    "    c=all_labels, # Color by true labels\n",
    "    cmap=cmap_binary, # Choose a colormap, e.g., 'viridis', 'plasma', 'coolwarm'\n",
    "    s=25,           # Marker size\n",
    "    alpha=0.7       # Transparency\n",
    ")\n",
    "\n",
    "# Add legend for true labels\n",
    "handles, _ = scatter.legend_elements() # Get default handles for the scatter points\n",
    "plt.legend(handles=handles, labels=legend_labels, title=\"True Labels\")\n",
    "\n",
    "plt.title('UMAP Projection of Model')\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# Identify indices for mass ratio = 0 and mass ratio != 0\n",
    "# Filter out NaNs if any were introduced\n",
    "valid_indices = ~np.isnan(ratios_in_order)\n",
    "zero_ratio_indices = np.where((ratios_in_order == 0) & valid_indices)[0]\n",
    "non_zero_ratio_indices = np.where((ratios_in_order != 0) & valid_indices)[0]\n",
    "\n",
    "# 1. Plot galaxies with non-zero mass ratio (continuous colormap)\n",
    "scatter_non_zero = plt.scatter(\n",
    "    umap_embedding[non_zero_ratio_indices, 0],\n",
    "    umap_embedding[non_zero_ratio_indices, 1],\n",
    "    c=ratios_in_order[non_zero_ratio_indices], # Color by mass ratio\n",
    "    cmap='magma',       # Choose a colormap for continuous data (e.g., 'viridis', 'plasma', 'magma')\n",
    "    alpha=0.7,\n",
    "    s = np.array(ratios_in_order[non_zero_ratio_indices])*100,\n",
    "    label='Mergers'\n",
    ")\n",
    "\n",
    "# Add a colorbar for the continuous mass ratios\n",
    "cbar = plt.colorbar(scatter_non_zero)\n",
    "cbar.set_label('Mass Ratio')\n",
    "\n",
    "# 2. Plot galaxies with mass ratio = 0 (distinct fixed color)\n",
    "scatter_zero = plt.scatter(\n",
    "    umap_embedding[zero_ratio_indices, 0],\n",
    "    umap_embedding[zero_ratio_indices, 1],\n",
    "    color='cornflowerblue',       # Choose a distinct color (e.g., 'red', 'blue', 'lime', 'cyan')\n",
    "    alpha=0.8,\n",
    "    s=20,               # Make them slightly larger or use a different marker for emphasis\n",
    "    marker='^',\n",
    "    label='Nonmergers'\n",
    ")\n",
    "\n",
    "plt.title('UMAP Projection (colored by Mass Ratio)')\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add a legend for the fixed-color 'Mass Ratio = 0' points\n",
    "plt.legend(loc='best') # 'best' attempts to place it where it won't overlap much\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = masses_in_order.min()\n",
    "vmax = masses_in_order.max()\n",
    "plt.figure(figsize=(8,6)) # Adjusted for colorbar\n",
    "\n",
    "# 1. Plot galaxies with non-zero mass ratio (continuous colormap)\n",
    "scatter_non_zero = plt.scatter(\n",
    "    umap_embedding[non_zero_ratio_indices, 0],\n",
    "    umap_embedding[non_zero_ratio_indices, 1],\n",
    "    c=masses_in_order[non_zero_ratio_indices], # Color by mass ratio\n",
    "    cmap='magma',#'magma',  \n",
    "    vmin=vmin, vmax=vmax,  # Sync color scale,\n",
    "    # Choose a colormap for continuous data (e.g., 'viridis', 'plasma', 'magma')\n",
    "    alpha=0.8,\n",
    "    s = 30,\n",
    "    label='Mergers'\n",
    ")\n",
    "\n",
    "# Add a colorbar for the continuous mass ratios\n",
    "cbar = plt.colorbar(scatter_non_zero)\n",
    "cbar.set_label(r'Log[Stellar Mass $M_\\odot$]', fontsize = 'x-large')\n",
    "cbar.ax.tick_params(labelsize='large')\n",
    "\n",
    "# 2. Plot galaxies with mass ratio = 0 (distinct fixed color)\n",
    "scatter_zero = plt.scatter(\n",
    "    umap_embedding[zero_ratio_indices, 0],\n",
    "    umap_embedding[zero_ratio_indices, 1],\n",
    "    c=masses_in_order[zero_ratio_indices],       # Choose a distinct color (e.g., 'red', 'blue', 'lime', 'cyan')\n",
    "    alpha=0.8,\n",
    "    cmap = 'magma',\n",
    "    vmin=vmin, vmax=vmax,  # Sync color scale\n",
    "    s=40,               # Make them slightly larger or use a different marker for emphasis\n",
    "    marker='^',\n",
    "    edgecolors='black',\n",
    "    linewidths=0.5,\n",
    "    label='Nonmergers'\n",
    ")\n",
    "\n",
    "#plt.title('UMAP projection (colored by Galaxy Mass)')\n",
    "# plt.xlabel('UMAP Component 1')\n",
    "# plt.ylabel('UMAP Component 2')\n",
    "plt.tick_params(axis='both',          # Apply to both x and y axes\n",
    "                which='both',         # Apply to both major and minor ticks\n",
    "                bottom=False,         # Turn off ticks along the bottom edge\n",
    "                top=False,            # Turn off ticks along the top edge\n",
    "                left=False,           # Turn off ticks along the left edge\n",
    "                right=False,          # Turn off ticks along the right edge\n",
    "                labelbottom=False,    # Turn off labels along the bottom edge\n",
    "                labelleft=False) \n",
    "# # Add a colorbar to show the mass scale\n",
    "# cbar = plt.colorbar(scatter)\n",
    "# cbar.set_label('Stellar Mass') # Update label with units\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('umap_stellarmass.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssfrs_in_order = np.array(np.array(sfrs_in_order)/((np.array(masses_in_order)**(10))))\n",
    "ssfrs_in_order = np.log10(ssfrs_in_order)\n",
    "vmin = ssfrs_in_order.min()\n",
    "vmax = ssfrs_in_order.max()\n",
    "#print(ssfrs_in_order)\n",
    "plt.figure(figsize=(8,6)) # Adjusted for colorbar\n",
    "# 1. Plot galaxies with non-zero mass ratio (continuous colormap)\n",
    "scatter_non_zero = plt.scatter(\n",
    "    umap_embedding[non_zero_ratio_indices, 0],\n",
    "    umap_embedding[non_zero_ratio_indices, 1],\n",
    "    c=ssfrs_in_order[non_zero_ratio_indices], # Color by mass ratio\n",
    "    cmap='magma',#'magma',  \n",
    "    vmin=vmin, vmax=vmax,  # Sync color scale,\n",
    "    # Choose a colormap for continuous data (e.g., 'viridis', 'plasma', 'magma')\n",
    "    alpha=0.8,\n",
    "    s = 30,\n",
    "    label='Mergers'\n",
    ")\n",
    "\n",
    "# Add a colorbar for the continuous mass ratios\n",
    "cbar = plt.colorbar(scatter_non_zero)\n",
    "cbar.set_label(r'Log[sSFR $M_\\odot/yr/M_\\star$]', fontsize = 'x-large')\n",
    "cbar.ax.tick_params(labelsize='large')\n",
    "# 2. Plot galaxies with mass ratio = 0 (distinct fixed color)\n",
    "scatter_zero = plt.scatter(\n",
    "    umap_embedding[zero_ratio_indices, 0],\n",
    "    umap_embedding[zero_ratio_indices, 1],\n",
    "    c=ssfrs_in_order[zero_ratio_indices],       # Choose a distinct color (e.g., 'red', 'blue', 'lime', 'cyan')\n",
    "    alpha=0.8,\n",
    "    cmap = 'magma',\n",
    "    vmin=vmin, vmax=vmax,  # Sync color scale\n",
    "    s=40,               # Make them slightly larger or use a different marker for emphasis\n",
    "    marker='^',\n",
    "    edgecolors='black',\n",
    "    linewidths=0.5,\n",
    "    label='Nonmergers'\n",
    ")\n",
    "\n",
    "# plt.title('UMAP projection (colored by sSFR)')\n",
    "# plt.xlabel('UMAP Component 1')\n",
    "# plt.ylabel('UMAP Component 2')\n",
    "plt.tick_params(axis='both',          # Apply to both x and y axes\n",
    "                which='both',         # Apply to both major and minor ticks\n",
    "                bottom=False,         # Turn off ticks along the bottom edge\n",
    "                top=False,            # Turn off ticks along the top edge\n",
    "                left=False,           # Turn off ticks along the left edge\n",
    "                right=False,          # Turn off ticks along the right edge\n",
    "                labelbottom=False,    # Turn off labels along the bottom edge\n",
    "                labelleft=False) \n",
    "# # Add a colorbar to show the mass scale\n",
    "# cbar = plt.colorbar(scatter)\n",
    "# cbar.set_label('Stellar Mass') # Update label with units\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('umap_ssfr.png', dpi = 300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin_mass = masses_in_order.min()\n",
    "vmax_mass = masses_in_order.max()\n",
    "vmin_ssfr = ssfrs_in_order.min()\n",
    "vmax_ssfr = ssfrs_in_order.max()\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (12, 6))\n",
    "\n",
    "# 1. Plot galaxies with non-zero mass ratio (continuous colormap)\n",
    "scatter_non_zero = ax1.scatter(\n",
    "    umap_embedding[non_zero_ratio_indices, 0],\n",
    "    umap_embedding[non_zero_ratio_indices, 1],\n",
    "    c=masses_in_order[non_zero_ratio_indices], # Color by mass ratio\n",
    "    cmap='magma',#'magma',  \n",
    "    vmin=vmin_mass, vmax=vmax_mass,  # Sync color scale,\n",
    "    # Choose a colormap for continuous data (e.g., 'viridis', 'plasma', 'magma')\n",
    "    alpha=0.8,\n",
    "    s = 30,\n",
    "    label='Mergers'\n",
    ")\n",
    "\n",
    "# Add a colorbar for the continuous mass ratios\n",
    "cbar = fig.colorbar(scatter_non_zero, ax=ax1)\n",
    "cbar.set_label(r'M$_\\star$ [Log$M_\\odot$]', fontsize='x-large')\n",
    "cbar.ax.tick_params(labelsize='large')\n",
    "\n",
    "# 2. Plot galaxies with mass ratio = 0 (distinct fixed color)\n",
    "scatter_zero = ax1.scatter(\n",
    "    umap_embedding[zero_ratio_indices, 0],\n",
    "    umap_embedding[zero_ratio_indices, 1],\n",
    "    c=masses_in_order[zero_ratio_indices],       # Choose a distinct color (e.g., 'red', 'blue', 'lime', 'cyan')\n",
    "    alpha=0.8,\n",
    "    cmap = 'magma',\n",
    "    vmin=vmin_mass, vmax=vmax_mass,  # Sync color scale\n",
    "    s=40,               # Make them slightly larger or use a different marker for emphasis\n",
    "    marker='^',\n",
    "    edgecolors='black',\n",
    "    linewidths=0.5,\n",
    "    label='Nonmergers'\n",
    ")\n",
    "\n",
    "\n",
    "ax1.tick_params(axis='both',          # Apply to both x and y axes\n",
    "                which='both',         # Apply to both major and minor ticks\n",
    "                bottom=False,         # Turn off ticks along the bottom edge\n",
    "                top=False,            # Turn off ticks along the top edge\n",
    "                left=False,           # Turn off ticks along the left edge\n",
    "                right=False,          # Turn off ticks along the right edge\n",
    "                labelbottom=False,    # Turn off labels along the bottom edge\n",
    "                labelleft=False) \n",
    "\n",
    "ax1.legend()\n",
    "\n",
    "scatter_non_zero = ax2.scatter(\n",
    "    umap_embedding[non_zero_ratio_indices, 0],\n",
    "    umap_embedding[non_zero_ratio_indices, 1],\n",
    "    c=ssfrs_in_order[non_zero_ratio_indices], # Color by mass ratio\n",
    "    cmap='magma',#'magma',  \n",
    "    vmin=vmin_ssfr, vmax=vmax_ssfr,  # Sync color scale,\n",
    "    # Choose a colormap for continuous data (e.g., 'viridis', 'plasma', 'magma')\n",
    "    alpha=0.8,\n",
    "    s = 30,\n",
    "    label='Mergers'\n",
    ")\n",
    "\n",
    "# Add a colorbar for the continuous mass ratios\n",
    "cbar2 = fig.colorbar(scatter_non_zero, ax=ax2)\n",
    "cbar2.set_label(r'sSFR [Logyr$^{-1}$]', fontsize='x-large')\n",
    "cbar2.ax.tick_params(labelsize='large')\n",
    "# 2. Plot galaxies with mass ratio = 0 (distinct fixed color)\n",
    "scatter_zero = ax2.scatter(\n",
    "    umap_embedding[zero_ratio_indices, 0],\n",
    "    umap_embedding[zero_ratio_indices, 1],\n",
    "    c=ssfrs_in_order[zero_ratio_indices],       # Choose a distinct color (e.g., 'red', 'blue', 'lime', 'cyan')\n",
    "    alpha=0.8,\n",
    "    cmap = 'magma',\n",
    "    vmin=vmin_ssfr, vmax=vmax_ssfr,  # Sync color scale\n",
    "    s=40,               # Make them slightly larger or use a different marker for emphasis\n",
    "    marker='^',\n",
    "    edgecolors='black',\n",
    "    linewidths=0.5,\n",
    "    label='Nonmergers'\n",
    ")\n",
    "\n",
    "# ax2.title('UMAP projection (colored by sSFR)')\n",
    "# ax2.xlabel('UMAP Component 1')\n",
    "# ax2.ylabel('UMAP Component 2')\n",
    "ax2.tick_params(axis='both',          # Apply to both x and y axes\n",
    "                which='both',         # Apply to both major and minor ticks\n",
    "                bottom=False,         # Turn off ticks along the bottom edge\n",
    "                top=False,            # Turn off ticks along the top edge\n",
    "                left=False,           # Turn off ticks along the left edge\n",
    "                right=False,          # Turn off ticks along the right edge\n",
    "                labelbottom=False,    # Turn off labels along the bottom edge\n",
    "                labelleft=False) \n",
    "# # Add a colorbar to show the mass scale\n",
    "# cbar = ax2.colorbar(scatter)\n",
    "# cbar.set_label('Stellar Mass') # Update label with units\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('UMAP_mass_ssfr_panel.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP clump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out which galaxies are in that clump so we can look at why they are so different\n",
    "print(all_names[umap_embedding[:,0] > 6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
